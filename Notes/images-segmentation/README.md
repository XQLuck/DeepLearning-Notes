# 图像分割(含语义/实例/全景分割)

## (1) 对图像分割的基本认识

（1）什么是超像素、语义分割、实例分割、全景分割？

图像分割（image segmentation）任务的定义是：根据某些规则将图片分成若干个特定的、具有独特性质的区域，并提出感兴趣目标的技术和过程。

目前图像分割任务发展出了以下几个子领域：语义分割（semantic segmentation）、实例分割（instance segmentation）以及今年刚兴起的新领域全景分割（panoptic segmentation）。

而想要理清三个子领域的区别就不得不提到关于图像分割中 things 和 stuff 的区别：图像中的内容可以按照是否有固定形状分为 things 类别和 stuff 类别，其中，人，车等有固定形状的物体属于 things 类别（可数名词通常属于 things）；天空，草地等没有固定形状的物体属于 stuff 类别（不可数名词属于 stuff）。

语义分割更注重「类别之间的区分」，而实例分割更注重「个体之间的区分」，以下图为例，从上到下分别是原图、语义分割结果和实例分割结果。语义分割会重点将前景里的人群和背景里树木、天空和草地分割开，但是它不区分人群的单独个体，如图中的人全部标记为红色，导致右边黄色框中的人无法辨别是一个人还是不同的人；而实例分割会重点将人群里的每一个人分割开，但是不在乎草地、树木和天空的分割。

- [超像素、语义分割、实例分割、全景分割 傻傻分不清？ - 知乎](https://zhuanlan.zhihu.com/p/50996404)
- [全景分割这一年，端到端之路 | 机器之心](https://www.jiqizhixin.com/articles/2018-12-24-12)

（2）什么是同物异谱、同谱异物？

同物异谱：在相同的地物上，由于周围环境、病虫害或者放射性物质等影响，造成的相同的物种但是其光谱曲线不同。

异物同谱：在某一谱段区，两个不同地物可能会呈现相同的谱线特征。这是同谱异物，也可能是同一个地物，处于不同的状态，如对太阳光相对角度不同，密度不同，含水量不同，生长环境影响光谱曲线，呈现不同的谱线特征。

这两种现象在主要依靠光谱信息进行分类的算法上影响是很大，很容易造成错分、误分，在 3D-CNN 上，利用空谱联合信息来处理高光谱影像，在某种程度上可以削弱同物异谱或者同谱异物的影响。

参考：[高光谱中的同物异谱及同谱异物现象](https://blog.csdn.net/u012193416/article/details/80683929)

（3）RGB图像、全色图像、多光谱图像、高光谱图像？

参考：[详细理解RGB图像、全色图像、多光谱图像、高光谱图像  - CSDN博客](https://blog.csdn.net/Chaolei3/article/details/79404806)

（4）什么是 SAR 图像？

SAR 是主动式侧视雷达系统，且成像几何属于斜距投影类型。因此 SAR 图像与光学图像在成像机理、几何特征、辐射特征等方面都有较大的区别。在进行 SAR 图像处理和应用前，需要了解 SAR 图像的基本特征。

——from：[SAR图像简介 - xuanzi_eli的博客 - CSDN博客](https://blog.csdn.net/xuanzi_eli/article/details/52334789)

（5）遥感图像处理和普通图像处理有哪些异同呢，本质区别是什么？

参考：[遥感图像处理和普通图像处理有哪些异同呢，本质区别是什么？ - 知乎](https://www.zhihu.com/question/29738706)

（6）什么是超分辨率？

超分辨率(Super-Resolution)即通过硬件或软件的方法提高原有图像的分辨率，通过一系列低分辨率的图像来得到一幅高分辨率的图像过程就是超分辨率重建。超分辨率重建的核心思想就是用时间带宽(获取同一场景的多帧图像序列)换取空间分辨率,实现时间分辨率向空间分辨率的转换。*——from：[超分辨率_百度百科](https://baike.baidu.com/item/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87)* 

超分辨率技术（Super-Resolution）是指从观测到的低分辨率图像重建出相应的高分辨率图像，在监控设备、卫星图像和医学影像等领域都有重要的应用价值。SR可分为两类:从多张低分辨率图像重建出高分辨率图像和从单张低分辨率图像重建出高分辨率图像。基于深度学习的SR，主要是基于单张低分辨率的重建方法，即Single Image Super-Resolution (SISR)。*——from：[深度学习在图像超分辨率重建中的应用 - 知乎](https://zhuanlan.zhihu.com/p/25532538)* 

（7）怎么理解掩膜（Mask）？





---



这是我早些时候整理的计算机视觉和图像分割资料，还算比较全面：[计算机视觉笔记及资料整理（含图像分割、目标检测）.md](./notes/计算机视觉笔记及资料整理（含图像分割、目标检测）.md)

> 含图像分割入门基础、图像分割的模型发展及介绍、图像分割数据集等等。

[语义分割相关资料总结 - 知乎](https://zhuanlan.zhihu.com/p/41976717)



---

我在幕布上的记录：[04-图像语义分割(含FCN、UNet、SegNet、PSPNet、Deeplabv1&v2&v3等)](https://mubu.com/doc/1OEfnuDXAc)

- 常规的深度卷积神经网络 (如 AlexNet 和 VGG ) 并不适用于密集预测的任务。首先，这些模型包含许多用于减小输入特征的空间维度的层。结果，这些层最终产生缺乏清晰细节的高度抽象的特征矢量。第二，全连接层在计算过程中具有固定的输入规模和松散的空间信息。

- 作为一个例子，试想通过一系列的卷积来传递图像，而不是使用池化和全连接层。我们将每次卷积都设置成步长为 1，padding 为「SAME」。通过这种处理，每一次卷积都保留了输入的空间维度。我们可以堆叠很多这种卷积，并最终得到一个分割模型。用于密集预测的全卷积神经网络。**请注意，不存在池化层和全连接层。**

- 这个模型可以输出形状为 [W,H,C] 的概率张量，其中 W 和 H 代表的是宽度和高度，C 代表的是类别标签的个数。在第三个维度上应用最大化函数会得到形状为 [W,H,1] 的张量。然后，我们计算真实图像和我们的预测的每个像素之间的交叉熵。最终，我们对计算结果取平均值，并且使用反向传播算法训练网络。

- **然而**，这个方法存在一个问题。正如前面所提到的，使用步长为 1，padding 为「SAME」，保留了输入的维度。但是，那样做的后果就是模型会极其耗费内存，而且计算复杂度也是很大的。

- 为了缓解这个问题，分割网络通常会有三个主要的组成部分：卷积层、降采样层和上采样层。

  - **①图像语义分割模型的编码器-解码器结构。**
    - 在卷积神经网络中实现降采样的常用方式有两个：通过改变卷积步长或者常规的池化操作。一般而言，降采样的目标就是减少给定特征图的空间维度。因此，降采样可以让我们在执行更深的卷积运算时不用过多地考虑内存。然而，这样一来在计算的时候会损失一些特征。
    - 值得注意的是，这个架构的第一部分看上去类似于普通的分类深度卷积神经网络。不同的是，其中没有设置全连接层。
    - 有很多基于编码器—解码器结构的神经网络实现。**FCNs、SegNet，以及 UNet 是最流行的几个。**
  - **②膨胀卷积，抛弃了池化层。**

  ——*Form [语义分割网络DeepLab-v3的架构设计思想和TensorFlow实现 | 机器之心](https://www.jiqizhixin.com/articles/deeplab-v3)*

  





## (2) 语义分割的发展梳理

在学习完常见的语义分割模型后，可以看下面这些文章再梳理下。

### 语义分割发展和历史

（1）[10分钟看懂全卷积神经网络（FCN）：语义分割深度模型先驱 - TinyMind](https://www.tinymind.cn/articles/3815)

所有的发展都是漫长的技术积累，加上一些外界条件满足时就会产生质变。我们简单总结了图像分割的几个时期：

**2000年之前，数字图像处理时我们采用方法基于几类：阈值分割、区域分割、边缘分割、纹理特征、聚类等。**

**2000年到2010年期间， 主要方法有四类：基于图论、聚类、分类以及聚类和分类结合。**

**2010年至今，神经网络模型的崛起和深度学习的发展，主要涉及到几种模型：**

![](https://file.ai100.com.cn/files/sogou-articles/original/fb9f37e6-e925-4142-904b-3707fb984cd4/fb9f37e6-e925-4142-904b-3707fb984cd4)

截至到2017年底，我们已经分化出了数以百计的模型结构。当然，经过从技术和原理上考究，我们发现了一个特点，那就是当前最成功的图像分割深度学习技术都是基于一个共同的先驱：FCN（Fully Convolutional Network，全卷积神经网络）。

发展历程：

- 2014年 FCN 模型，主要贡献为在语义分割问题中推广使用端对端卷积神经网络，使用反卷积进行上采样

- 2015年 U-net 模型，构建了一套完整 的编码解码器

- 2015年 SegNet 模型，将最大池化转换为解码器来提高分辨率

- 2015年 Dilated Convolutions（空洞卷积），更广范围内提高了内容的聚合并不降低分辨率

- 2016年 DeepLab v1&v2

- 2016年 RefineNet 使用残差连接，降低了内存使用量，提高了模块间的特征融合

- 2016年 PSPNet 模型

- 2017年 Large Kernel Matters

- 2017年 DeepLab V3

以上几种模型可以按照语义分割模型的独有方法进行分类，如专门池化（PSPNet、DeepLab），编码器-解码器架构（SegNet、E-Net），多尺度处理（DeepLab）、条件随机场（CRFRNN）、空洞卷积（DiatedNet、DeepLab）和跳跃连接（FCN）。



（2）[深度学习（十九）——FCN, SegNet, DeconvNet, DeepLab, ENet, GCN](https://blog.csdn.net/antkillerfarm/article/details/79524417)

**前DL时代的语义分割：** 

Grab cut是微软剑桥研究院于2004年提出的著名交互式图像语义分割方法。与N-cut一样，grab cut同样也是基于图划分，不过grab cut是其改进版本，可以看作迭代式的语义分割算法。Grab cut利用了图像中的纹理（颜色）信息和边界（反差）信息，只要少量的用户交互操作即可得到比较好的前后背景分割结果。

在Grab cut中，RGB图像的前景和背景分别用一个高斯混合模型（Gaussian mixture model, GMM）来建模。两个GMM分别用以刻画某像素属于前景或背景的概率，每个GMM高斯部件（Gaussian component）个数一般设为k=5。接下来，利用吉布斯能量方程（Gibbs energy function）对整张图像进行全局刻画，而后迭代求取使得能量方程达到最优值的参数作为两个GMM的最优参数。GMM确定后，某像素属于前景或背景的概率就随之确定下来。

在与用户交互的过程中，Grab cut提供两种交互方式：一种以包围框（Bounding box）为辅助信息；另一种以涂写的线条（Scribbled line）作为辅助信息。以下图为例，用户在开始时提供一个包围框，grab cut默认的认为框中像素中包含主要物体／前景，此后经过迭代图划分求解，即可返回扣出的前景结果，可以发现即使是对于背景稍微复杂一些的图像，grab cut仍有不俗表现。

不过，在处理下图时，grab cut的分割效果则不能令人满意。此时，需要额外人为的提供更强的辅助信息：用红色线条／点标明背景区域，同时用白色线条标明前景区域。在此基础上，再次运行grab cut算法求取最优解即可得到较为满意的语义分割结果。Grab cut虽效果优良，但缺点也非常明显，一是仅能处理二类语义分割问题，二是需要人为干预而不能做到完全自动化。

不难看出，前DL时代的语义分割工作多是根据图像像素自身的低阶视觉信息（Low-level visual cues）来进行图像分割。由于这样的方法没有算法训练阶段，因此往往计算复杂度不高，但是在较困难的分割任务上（如果不提供人为的辅助信息），其分割效果并不能令人满意。



（3）[基于深度学习的语义分割简述及初探[译] - AIUAI](https://www.aiuai.cn/aifarm599.html)

语义分割是对图像的一种更精细的推断与理解，由粗到细为：

- 图像分类 - 初级的图片理解，其对整张图片进行整体理解.
- 目标定位与检测 - 不仅提供图像内的类别，还包括相对于物体类别的空间为位置信息.
- 语义分割 - 对每个图像像素进行密集预测，得到像素类别信息.

。。。

[1] 基于区域的语义分割

[2] 基于 FCN 的语义分割

[3] 弱监督语义分割



### 语义分割模型发展

（1）[语义分割中的深度学习方法全解：从FCN、SegNet到各代DeepLab - 知乎](https://zhuanlan.zhihu.com/p/27794982)

该文要点：

1. FCN网络；
2. SegNet网络；
3. 空洞卷积(Dilated Convolutions)；
4. DeepLab (v1和v2)；
5. RefineNet；
6. PSPNet；
7. 大内核(Large Kernel Matters)；
8. DeepLab v3；

对于上面的每篇论文，将会分别指出主要贡献并进行解释，也贴出了这些结构在 VOC2012 数据集中的测试分值IOU。

（2）[主要语义分割网络模型概览[转] - AIUAI](https://www.aiuai.cn/aifarm602.html)

图像的语义分割是将输入图像中的每个像素分配一个语义类别，以得到像素化的密集分类。

虽然自 2007 年以来，语义分割/场景解析一直是计算机视觉社区的一部分，但与计算机视觉中的其他领域很相似，自 2014 年 Long 等人首次使用全卷积神经网络对自然图像进行端到端分割，语义分割才有了重大突破。

本文作者总结了 FCN、SegNet、U-Net、FC-Densenet E-Net 和 Link-Net、RefineNet、PSPNet、Mask-RCNN 以及一些半监督方法，如 DecoupledNet 和 GAN-SS，并为其中的一些网络提供了 PyTorch 实现. 在文章的最后一部分，作者总结了一些流行的数据集，并展示了一些网络训练的结果。



